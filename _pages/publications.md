---
layout: single
title: ""
permalink: /publications/
author_profile: true
---
# <i class="fa fa-fw fa-paste"></i> My [Google Scholar](https://scholar.google.com/citations?user=6TXLCaYAAAAJ&hl=en) #

[LLM Safety Alignment is Divergence Estimation in Disguise](https://www.arxiv.org/abs/2502.00657)\
**Rajdeep Haldar**, Ziyi Wang, Yue Xing, Guang Lin, Qifan Song (2025)

[Adversarial Vulnerability as a Consequence of Manifold Inseparability](https://arxiv.org/pdf/2410.06921)\
**Rajdeep Haldar**, Yue Xing, Guang Lin, Qifan Song (2024).

[Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability](https://proceedings.mlr.press/v238/haldar24a.html)\
**Rajdeep Haldar**, Yue Xing, Qifan Song\
[AISTATS 2024] _27th International Conference on Artificial Intelligence and Statistics, Valencia, Spain._

[On Neural Network Approximation of Ideal Adversarial Attack and Convergence of Adversarial Training](https://arxiv.org/abs/2307.16099)\
**Rajdeep Haldar**, Qifan Song (2023)\
_Under revision for SIMODS_



